diff --git a/OpenCL/m12500-pure.cl b/OpenCL/m12500-pure.cl
index 24b0a8f0..c17bdb17 100644
--- a/OpenCL/m12500-pure.cl
+++ b/OpenCL/m12500-pure.cl
@@ -17,14 +17,6 @@
 
 #define ROUNDS 0x40000
 
-#define PUTCHAR(a,p,c) ((u8 *)(a))[(p)] = (u8) (c)
-#define GETCHAR(a,p)   ((u8 *)(a))[(p)]
-
-#define PUTCHAR_BE(a,p,c) ((u8 *)(a))[(p) ^ 3] = (u8) (c)
-#define GETCHAR_BE(a,p)   ((u8 *)(a))[(p) ^ 3]
-
-#define MIN(a,b) (((a) < (b)) ? (a) : (b))
-
 typedef struct pbkdf2_sha1
 {
   u32 salt_buf[64];
@@ -33,7 +25,11 @@ typedef struct pbkdf2_sha1
 
 typedef struct rar3_tmp
 {
-  u32 dgst[17][5];
+  u32 dgst[5];
+
+  u32 w[66]; // 256 byte pass + 8 byte salt
+
+  u32 iv[4];
 
 } rar3_tmp_t;
 
@@ -148,19 +144,82 @@ KERNEL_FQ void m12500_init (KERN_ATTR_TMPS_ESALT (rar3_tmp_t, pbkdf2_sha1_t))
 
   if (gid >= gid_max) return;
 
-  tmps[gid].dgst[0][0] = SHA1M_A;
-  tmps[gid].dgst[0][1] = SHA1M_B;
-  tmps[gid].dgst[0][2] = SHA1M_C;
-  tmps[gid].dgst[0][3] = SHA1M_D;
-  tmps[gid].dgst[0][4] = SHA1M_E;
+  tmps[gid].dgst[0] = SHA1M_A;
+  tmps[gid].dgst[1] = SHA1M_B;
+  tmps[gid].dgst[2] = SHA1M_C;
+  tmps[gid].dgst[3] = SHA1M_D;
+  tmps[gid].dgst[4] = SHA1M_E;
 
-  /**
-   * context save
-   */
+  // store pass and salt in tmps:
 
-  sha1_ctx_t ctx;
+  const u32 pw_len = pws[gid].pw_len;
+
+  // first set the utf16le pass:
+
+  u32 w[80] = { 0 };
+
+  for (u32 i = 0, j = 0, k = 0; i < pw_len; i += 16, j += 4, k += 8)
+  {
+    u32 a[4];
+
+    a[0] = pws[gid].i[j + 0];
+    a[1] = pws[gid].i[j + 1];
+    a[2] = pws[gid].i[j + 2];
+    a[3] = pws[gid].i[j + 3];
+
+    u32 b[4];
+    u32 c[4];
+
+    make_utf16le (a, b, c);
+
+    w[k + 0] = hc_swap32_S (b[0]);
+    w[k + 1] = hc_swap32_S (b[1]);
+    w[k + 2] = hc_swap32_S (b[2]);
+    w[k + 3] = hc_swap32_S (b[3]);
+    w[k + 4] = hc_swap32_S (c[0]);
+    w[k + 5] = hc_swap32_S (c[1]);
+    w[k + 6] = hc_swap32_S (c[2]);
+    w[k + 7] = hc_swap32_S (c[3]);
+  }
+
+  // append salt:
+
+  const u32 salt_idx = (pw_len * 2) / 4;
+  const u32 salt_off = (pw_len * 2) & 3;
+
+  u32 salt_buf[3];
+
+  salt_buf[0] = hc_swap32_S (salt_bufs[salt_pos].salt_buf[0]); // swap needed due to -O kernel
+  salt_buf[1] = hc_swap32_S (salt_bufs[salt_pos].salt_buf[1]);
+  salt_buf[2] = 0;
 
-  sha1_init (&ctx);
+  // switch buffer by offset (can only be 0 or 2 because of utf16):
+
+  if (salt_off == 2) // or just: if (salt_off)
+  {
+    salt_buf[2] = (salt_buf[1] << 16);
+    salt_buf[1] = (salt_buf[1] >> 16) | (salt_buf[0] << 16);
+    salt_buf[0] = (salt_buf[0] >> 16);
+  }
+
+  w[salt_idx] |= salt_buf[0];
+
+  w[salt_idx + 1] = salt_buf[1];
+  w[salt_idx + 2] = salt_buf[2];
+
+  // store initial w[] (pass and salt) in tmps:
+
+  for (u32 i = 0; i < 66; i++)
+  {
+    tmps[gid].w[i] = w[i];
+  }
+
+  // iv:
+
+  tmps[gid].iv[0] = 0;
+  tmps[gid].iv[1] = 0;
+  tmps[gid].iv[2] = 0;
+  tmps[gid].iv[3] = 0;
 }
 
 KERNEL_FQ void m12500_loop (KERN_ATTR_TMPS_ESALT (rar3_tmp_t, pbkdf2_sha1_t))
@@ -175,62 +234,99 @@ KERNEL_FQ void m12500_loop (KERN_ATTR_TMPS_ESALT (rar3_tmp_t, pbkdf2_sha1_t))
 
   const u32 pw_len = pws[gid].pw_len;
 
-  u32 w[64] = { 0 };
+  const u32 salt_len = 8;
+
+  const u32 pw_salt_len = (pw_len * 2) + salt_len;
+
+  const u32 p3 = pw_salt_len + 3;
+
+  u32 w[80] = { 0 }; // 64 byte aligned
 
-  for (u32 i = 0, idx = 0; i < pw_len; i += 4, idx += 1)
+  for (u32 i = 0; i < 66; i++)
   {
-    w[idx] = pws[gid].i[idx];
+    w[i] = tmps[gid].w[i];
   }
 
-  u32 salt_buf[16];
-
-  salt_buf[ 0] = salt_bufs[salt_pos].salt_buf[0];
-  salt_buf[ 1] = salt_bufs[salt_pos].salt_buf[1];
-  salt_buf[ 2] = 0;
-  salt_buf[ 3] = 0;
-  salt_buf[ 4] = 0;
-  salt_buf[ 5] = 0;
-  salt_buf[ 6] = 0;
-  salt_buf[ 7] = 0;
-  salt_buf[ 8] = 0;
-  salt_buf[ 9] = 0;
-  salt_buf[10] = 0;
-  salt_buf[11] = 0;
-  salt_buf[12] = 0;
-  salt_buf[13] = 0;
-  salt_buf[14] = 0;
-  salt_buf[15] = 0;
-
-  const u32 salt_len = 8;
+  // update IV:
 
   const u32 init_pos = loop_pos / (ROUNDS / 16);
 
+  sha1_ctx_t ctx_iv;
+
+  sha1_init (&ctx_iv);
+
+  ctx_iv.h[0] = tmps[gid].dgst[0];
+  ctx_iv.h[1] = tmps[gid].dgst[1];
+  ctx_iv.h[2] = tmps[gid].dgst[2];
+  ctx_iv.h[3] = tmps[gid].dgst[3];
+  ctx_iv.h[4] = tmps[gid].dgst[4];
+
+  ctx_iv.len = loop_pos * p3;
+
+  sha1_update (&ctx_iv, w, pw_salt_len);
+
+  memcat8c_be (ctx_iv.w0, ctx_iv.w1, ctx_iv.w2, ctx_iv.w3, ctx_iv.len, hc_swap32_S (loop_pos), ctx_iv.h);
+
+  ctx_iv.len += 3;
+
+
+  // copy the context from ctx_iv to ctx:
+
   sha1_ctx_t ctx;
 
-  sha1_init (&ctx);
+  ctx.h[0] = ctx_iv.h[0];
+  ctx.h[1] = ctx_iv.h[1];
+  ctx.h[2] = ctx_iv.h[2];
+  ctx.h[3] = ctx_iv.h[3];
+  ctx.h[4] = ctx_iv.h[4];
 
-  ctx.h[0] = tmps[gid].dgst[init_pos][0];
-  ctx.h[1] = tmps[gid].dgst[init_pos][1];
-  ctx.h[2] = tmps[gid].dgst[init_pos][2];
-  ctx.h[3] = tmps[gid].dgst[init_pos][3];
-  ctx.h[4] = tmps[gid].dgst[init_pos][4];
+  ctx.w0[0] = ctx_iv.w0[0];
+  ctx.w0[1] = ctx_iv.w0[1];
+  ctx.w0[2] = ctx_iv.w0[2];
+  ctx.w0[3] = ctx_iv.w0[3];
 
-  for (u32 i = 0, j = loop_pos; i < 16384; i++, j++)
-  {
-    sha1_update_utf16le_swap (&ctx, w, pw_len);
+  ctx.w1[0] = ctx_iv.w1[0];
+  ctx.w1[1] = ctx_iv.w1[1];
+  ctx.w1[2] = ctx_iv.w1[2];
+  ctx.w1[3] = ctx_iv.w1[3];
+
+  ctx.w2[0] = ctx_iv.w2[0];
+  ctx.w2[1] = ctx_iv.w2[1];
+  ctx.w2[2] = ctx_iv.w2[2];
+  ctx.w2[3] = ctx_iv.w2[3];
+
+  ctx.w3[0] = ctx_iv.w3[0];
+  ctx.w3[1] = ctx_iv.w3[1];
+  ctx.w3[2] = ctx_iv.w3[2];
+  ctx.w3[3] = ctx_iv.w3[3];
 
-    sha1_update_swap (&ctx, salt_buf, salt_len);
+  ctx.len = p3; // or ctx_iv.len ?
+
+  // final () for the IV byte:
+
+  sha1_final (&ctx_iv);
+
+  const u32 iv_idx = init_pos / 4;
+  const u32 iv_off = init_pos & 3;
+
+  tmps[gid].iv[iv_idx] |= (ctx_iv.h[4] & 0xff) << (iv_off << 3);
+
+  // main loop:
+
+  for (u32 i = 0, j = (loop_pos + 1); i < 16383; i++, j++)
+  {
+    sha1_update (&ctx, w, pw_salt_len);
 
     memcat8c_be (ctx.w0, ctx.w1, ctx.w2, ctx.w3, ctx.len, hc_swap32_S (j), ctx.h);
 
     ctx.len += 3;
   }
 
-  tmps[gid].dgst[init_pos + 1][0] = ctx.h[0];
-  tmps[gid].dgst[init_pos + 1][1] = ctx.h[1];
-  tmps[gid].dgst[init_pos + 1][2] = ctx.h[2];
-  tmps[gid].dgst[init_pos + 1][3] = ctx.h[3];
-  tmps[gid].dgst[init_pos + 1][4] = ctx.h[4];
+  tmps[gid].dgst[0] = ctx.h[0];
+  tmps[gid].dgst[1] = ctx.h[1];
+  tmps[gid].dgst[2] = ctx.h[2];
+  tmps[gid].dgst[3] = ctx.h[3];
+  tmps[gid].dgst[4] = ctx.h[4];
 }
 
 KERNEL_FQ void m12500_comp (KERN_ATTR_TMPS_ESALT (rar3_tmp_t, pbkdf2_sha1_t))
@@ -298,43 +394,19 @@ KERNEL_FQ void m12500_comp (KERN_ATTR_TMPS_ESALT (rar3_tmp_t, pbkdf2_sha1_t))
 
   const u32 pw_len = pws[gid].pw_len;
 
-  u32 w[64] = { 0 };
-
-  for (u32 i = 0, idx = 0; i < pw_len; i += 4, idx += 1)
-  {
-    w[idx] = pws[gid].i[idx];
-  }
-
-  u32 salt_buf[16];
-
-  salt_buf[ 0] = salt_bufs[salt_pos].salt_buf[0];
-  salt_buf[ 1] = salt_bufs[salt_pos].salt_buf[1];
-  salt_buf[ 2] = 0;
-  salt_buf[ 3] = 0;
-  salt_buf[ 4] = 0;
-  salt_buf[ 5] = 0;
-  salt_buf[ 6] = 0;
-  salt_buf[ 7] = 0;
-  salt_buf[ 8] = 0;
-  salt_buf[ 9] = 0;
-  salt_buf[10] = 0;
-  salt_buf[11] = 0;
-  salt_buf[12] = 0;
-  salt_buf[13] = 0;
-  salt_buf[14] = 0;
-  salt_buf[15] = 0;
-
   const u32 salt_len = 8;
 
-  const u32 p3 = (pw_len * 2) + salt_len + 3;
+  const u32 pw_salt_len = (pw_len * 2) + salt_len;
+
+  const u32 p3 = pw_salt_len + 3;
 
   u32 h[5];
 
-  h[0] = tmps[gid].dgst[16][0];
-  h[1] = tmps[gid].dgst[16][1];
-  h[2] = tmps[gid].dgst[16][2];
-  h[3] = tmps[gid].dgst[16][3];
-  h[4] = tmps[gid].dgst[16][4];
+  h[0] = tmps[gid].dgst[0];
+  h[1] = tmps[gid].dgst[1];
+  h[2] = tmps[gid].dgst[2];
+  h[3] = tmps[gid].dgst[3];
+  h[4] = tmps[gid].dgst[4];
 
   u32 w0[4];
   u32 w1[4];
@@ -382,46 +454,13 @@ KERNEL_FQ void m12500_comp (KERN_ATTR_TMPS_ESALT (rar3_tmp_t, pbkdf2_sha1_t))
 
   AES128_decrypt (ks, data, out, s_td0, s_td1, s_td2, s_td3, s_td4);
 
-  u32 iv[4];
-
-  iv[0] = 0;
-  iv[1] = 0;
-  iv[2] = 0;
-  iv[3] = 0;
-
-  for (int i = 0; i < 16; i++)
-  {
-    sha1_ctx_t ctx;
-
-    sha1_init (&ctx);
-
-    ctx.h[0] = tmps[gid].dgst[i][0];
-    ctx.h[1] = tmps[gid].dgst[i][1];
-    ctx.h[2] = tmps[gid].dgst[i][2];
-    ctx.h[3] = tmps[gid].dgst[i][3];
-    ctx.h[4] = tmps[gid].dgst[i][4];
+  u32 iv[2];
 
-    const u32 iter_pos = i * (ROUNDS / 16);
-
-    ctx.len = iter_pos * p3;
-
-    sha1_update_utf16le_swap (&ctx, w, pw_len);
-
-    sha1_update_swap (&ctx, salt_buf, salt_len);
-
-    memcat8c_be (ctx.w0, ctx.w1, ctx.w2, ctx.w3, ctx.len, hc_swap32_S (iter_pos), ctx.h);
-
-    ctx.len += 3;
-
-    sha1_final (&ctx);
-
-    PUTCHAR (iv, i, ctx.h[4] & 0xff);
-  }
+  iv[0] = tmps[gid].iv[0];
+  iv[1] = tmps[gid].iv[1];
 
   out[0] ^= hc_swap32_S (iv[0]);
   out[1] ^= hc_swap32_S (iv[1]);
-  out[2] ^= hc_swap32_S (iv[2]);
-  out[3] ^= hc_swap32_S (iv[3]);
 
   const u32 r0 = out[0];
   const u32 r1 = out[1];
diff --git a/src/modules/module_12500.c b/src/modules/module_12500.c
index 6e5c4663..07c531f6 100644
--- a/src/modules/module_12500.c
+++ b/src/modules/module_12500.c
@@ -42,16 +42,33 @@ const char *module_st_pass        (MAYBE_UNUSED const hashconfig_t *hashconfig,
 
 typedef struct rar3_tmp
 {
-  u32 dgst[17][5];
+  u32 dgst[5];
+
+  u32 w[66]; // 256 byte pass + 8 byte salt
+
+  u32 iv[4];
 
 } rar3_tmp_t;
 
+typedef struct rar3_tmp_optimized
+{
+  u32 dgst[17][5];
+
+} rar3_tmp_optimized_t;
+
 static const int   ROUNDS_RAR3    = 262144;
 static const char *SIGNATURE_RAR3 = "$RAR3$";
 
 u64 module_tmp_size (MAYBE_UNUSED const hashconfig_t *hashconfig, MAYBE_UNUSED const user_options_t *user_options, MAYBE_UNUSED const user_options_extra_t *user_options_extra)
 {
-  const u64 tmp_size = (const u64) sizeof (rar3_tmp_t);
+  const bool optimized_kernel = (hashconfig->opti_type & OPTI_TYPE_OPTIMIZED_KERNEL);
+
+  u64 tmp_size = (u64) sizeof (rar3_tmp_t);
+
+  if (optimized_kernel == true)
+  {
+    tmp_size = (u64) sizeof (rar3_tmp_optimized_t);
+  }
 
   return tmp_size;
 }
